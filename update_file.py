# -*- coding: utf-8 -*-
"""update file.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rxa8BtJr3xtcMYwEG4CSTjGeT0Ihn2qP
"""

pip install fastapi uvicorn openai requests

pip install nest-asyncio pyngrok

from fastapi import FastAPI
from pydantic import BaseModel
import openai
import requests
import json

app = FastAPI()

# üîê API Keys
openai.api_key = "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"
huggingface_api_key = "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"  # For using Hugging Face APIs

# --------------------
# Real API Implementations
# --------------------

def find_tiffin_services(location: str):
    # Use OpenAI GPT to generate tiffin services dynamically
    prompt = f"Suggest popular tiffin and food delivery services available in {location} for office workers."
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

def find_room_near_office(location: str):
    # Use OpenAI to suggest rental options
    prompt = f"List affordable rental rooms or PGs near {location} suitable for a working professional."
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

def find_colleagues_nearby(company_name: str):
    # Fake ML logic (Normally needs a real database)
    return f"Feature to find colleagues from {company_name} nearby is under development. Stay tuned!"

def estimate_local_costs(city: str):
    # Use Hugging Face text generation model to create estimated cost summary
    url = "https://api-inference.huggingface.co/models/gpt2"
    headers = {"Authorization": f"Bearer {huggingface_api_key}"}
    payload = {"inputs": f"What is the estimated daily cost of living in {city} in India?"}
    response = requests.post(url, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()[0]['generated_text']
    else:
        return "Unable to fetch cost estimates currently."

def assess_safety(city: str):
    # Use OpenAI GPT to assess city safety
    prompt = f"Provide a safety rating out of 5 and brief safety advice for traveling in {city}."
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

def trip_planner(destination: str):
    # Use OpenAI GPT to create a travel plan
    prompt = f"Create a 2-day trip plan to {destination}, include main attractions, local foods, and estimated total cost."
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

def compare_cities(city1: str, city2: str):
    # Use OpenAI GPT to compare two cities
    prompt = f"Compare {city1} and {city2} in terms of cost of living, job opportunities, safety, and quality of life."
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

# --------------------
# Request Body Schema
# --------------------

class UserRequest(BaseModel):
    user_query: str

# --------------------
# FastAPI Route
# --------------------

@app.post("/chat")
async def chat_with_llm(user_req: UserRequest):
    # Function list for OpenAI Function Calling
    functions = [
        {
            "name": "find_tiffin_services",
            "description": "Finds tiffin providers in a specific location",
            "parameters": {
                "type": "object",
                "properties": {"location": {"type": "string"}},
                "required": ["location"],
            },
        },
        {
            "name": "find_room_near_office",
            "description": "Finds rental rooms or PGs near a workplace",
            "parameters": {
                "type": "object",
                "properties": {"location": {"type": "string"}},
                "required": ["location"],
            },
        },
        {
            "name": "find_colleagues_nearby",
            "description": "Finds colleagues working in the same company nearby",
            "parameters": {
                "type": "object",
                "properties": {"company_name": {"type": "string"}},
                "required": ["company_name"],
            },
        },
        {
            "name": "estimate_local_costs",
            "description": "Estimates local transport, food, and living costs",
            "parameters": {
                "type": "object",
                "properties": {"city": {"type": "string"}},
                "required": ["city"],
            },
        },
        {
            "name": "assess_safety",
            "description": "Provides a safety rating for a city or area",
            "parameters": {
                "type": "object",
                "properties": {"city": {"type": "string"}},
                "required": ["city"],
            },
        },
        {
            "name": "trip_planner",
            "description": "Creates a travel plan and cost estimate",
            "parameters": {
                "type": "object",
                "properties": {"destination": {"type": "string"}},
                "required": ["destination"],
            },
        },
        {
            "name": "compare_cities",
            "description": "Compares two cities for living, job, or travel",
            "parameters": {
                "type": "object",
                "properties": {"city1": {"type": "string"}, "city2": {"type": "string"}},
                "required": ["city1", "city2"],
            },
        },
    ]

    messages = [{"role": "user", "content": user_req.user_query}]

    # Call GPT
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages,
        functions=functions,
        function_call="auto"
    )

    message = response["choices"][0]["message"]

    if message.get("function_call"):
        function_name = message["function_call"]["name"]
        arguments = json.loads(message["function_call"]["arguments"])

        function_map = {
            "find_tiffin_services": find_tiffin_services,
            "find_room_near_office": find_room_near_office,
            "find_colleagues_nearby": find_colleagues_nearby,
            "estimate_local_costs": estimate_local_costs,
            "assess_safety": assess_safety,
            "trip_planner": trip_planner,
            "compare_cities": compare_cities,
        }

        func = function_map.get(function_name)

        if func:
            result = func(**arguments)
        else:
            result = "Function not implemented."

        return {"response": result}

    else:
        return {"response": message["content"]}

